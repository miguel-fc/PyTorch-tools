# -*- coding: utf-8 -*-
"""pepon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/miguel-fc/PyTorch-tools/blob/main/pepon.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# Import Python related required packages
import io
import cv2
import gdown
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
# %matplotlib inline
import plotly.express as px
# matplotlib.use('agg')
# plt.ioff()
from sklearn.metrics import mean_squared_error
from scipy.stats import gaussian_kde, norm
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.manifold import TSNE
from sklearn.metrics import mean_squared_error
import pandas as pd
from tqdm import tqdm

#Downloand numpy arrays for neutron reflectivity curves and parameters used to generate 
#them
!gdown "https://drive.google.com/uc?id=1--SS7PoObNsKwwN8Hg__ZBRvPCqqEBpA"
!gdown "https://drive.google.com/uc?id=1SmWTmLlvg-cEyzXIlt8ik286pQ4nE86G"

#Stored those numpy arrays
sld_arr = np.load('sld_fp34.npy')
params_arr = np.load('params_fp34.npy')

#Import torch related packages
import torch
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader,random_split, Dataset, TensorDataset
# import torch.utils.data as data_utils
from torch import nn
import torch.nn.functional as F
import torch.optim as optim

def split_input_arrays(in_data,label_data,size_split):

    xtr, xjunk, ytr, yjunk = train_test_split(in_data,label_data,train_size=size_split)
    xv, xte, yv, yte = train_test_split(xjunk,yjunk, test_size=0.5)
    print('xtrain.shape, ytrain.shape, xval.shape, yval.shape, xtest.shape, ytest.shape')
    print(xtr.shape, ytr.shape, xv.shape, yv.shape, xte.shape, yte.shape)
    return xtr, ytr, xv, yv, xte, yte

#Create dataset and dataloaders from splitted arrays
def get_dataloaders_fromsplitarrays(xtr,ytr,xv,yv,xte,yte,batch_size):

    tr_set = torch.utils.data.TensorDataset(torch.from_numpy(xtr).float(), torch.from_numpy(ytr).float())
    tr_load = torch.utils.data.DataLoader(tr_set, batch_size=batch_size, shuffle=True)

    va_set = torch.utils.data.TensorDataset(torch.from_numpy(xv).float(), torch.from_numpy(yv).float())
    va_load = torch.utils.data.DataLoader(va_set, batch_size=batch_size, shuffle=True)

    te_set = torch.utils.data.TensorDataset(torch.from_numpy(xte).float(), torch.from_numpy(yte).float())
    te_load = torch.utils.data.DataLoader(te_set, batch_size=batch_size, shuffle=True)

    return tr_set, va_set, te_set, tr_load, va_load, te_load

xtrain, ytrain, xval, yval, xtest, ytest = \
split_input_arrays(sld_arr,params_arr, size_split=0.8)

train_dataset, valid_dataset, test_dataset, train_loader, valid_loader, test_loader = \
get_dataloaders_fromsplitarrays(xtrain,ytrain,xval,yval,xtest,yval,batch_size=50)

class Encoder(nn.Module):
    
    def __init__(self,encoded_space_dim,dim1,dim2):
        super().__init__()

        self.encoder = nn.Sequential(
        nn.Linear(dim1 * dim2, 500),
        nn.ReLU(True),
        nn.Linear(500, 500),
        nn.ReLU(True),
        nn.Linear(500,encoded_space_dim))
        
    def forward(self, x):
        x = self.encoder(x)
        return x

class Decoder(nn.Module):
    
    def __init__(self,encoded_space_dim,dim1,dim2):
        super().__init__()

        self.decoder = nn.Sequential(
        nn.Linear(encoded_space_dim, 500),
        nn.ReLU(True),
        nn.Linear(500, 500),
        nn.ReLU(True),
        nn.Linear(500, dim1 * dim2))
        
    def forward(self, x):
        x = self.decoder(x)
        return x

loss_fn = torch.nn.MSELoss()
lr= 0.001
torch.manual_seed(0)

#Dimension of the latent space and of the graphs
d = 2
in_d1 = 2
in_d2 = 128


encoder = Encoder(encoded_space_dim=d,dim1=in_d1,dim2=in_d2)
decoder = Decoder(encoded_space_dim=d,dim1=in_d1,dim2=in_d2)

params_to_optimize = [
    {'params': encoder.parameters()},
    {'params': decoder.parameters()}
]

optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print(f'Selected device: {device}')

#Move encoder to device
encoder.to(device)

#Move decoder to device
decoder.to(device)

### Training function
def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):
    encoder.train()
    decoder.train()
    train_loss = []
    for data,label in dataloader: 
        img = data
        img = img.view(img.size(0), -1).to(device)  
        label = label.to(device)
        latent = encoder(img)
        decoded_img = decoder(latent)
        loss = loss_fn(decoded_img, img)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        train_loss.append(loss.detach().cpu().numpy())

    return np.mean(train_loss)

### Valid function
def valid_epoch(encoder, decoder, device, dataloader, loss_fn):
    encoder.eval()
    decoder.eval()
    with torch.no_grad(): 
        list_decoded_img = []
        list_img = []
        for  data, label in dataloader:
            img = data
            img = img.view(img.size(0), -1).to(device) 
            label = label.to(device)
            latent = encoder(img)
            decoded_img = decoder(latent)
            list_decoded_img.append(decoded_img.cpu())
            list_img.append(img.cpu())
        list_decoded_img = torch.cat(list_decoded_img)
        list_img = torch.cat(list_img) 
        val_loss = loss_fn(list_decoded_img, list_img)
    return val_loss.data

def plot_ae_outputs(encoder,decoder,dataset,device,n=10):
    plt.figure(figsize=(26,5.5))
    for i in range(10):
      ax = plt.subplot(2,n,i+1)
      img,_ = dataset[i]
      #Notice that below i'm loading an image only, so it needs to be flatten
      #before entering the network
      img = torch.flatten(img).to(device)
      encoder.eval().to(device)
      decoder.eval().to(device)
      with torch.no_grad():
        decoded_img = decoder(encoder(img))
      plt.plot(img.cpu().reshape(2,128).numpy()[0],img.cpu().reshape(2,128).numpy()[1]) 
      if i == n//2:
        ax.set_title('Original images')
      ax = plt.subplot(2, n, i + 1 + n) 
      plt.plot(decoded_img.cpu().reshape(2,128).numpy()[0],decoded_img.cpu().reshape(2,128).numpy()[1]) 
      if i == n//2:
         ax.set_title('Reconstructed images')
    plt.show()

num_epochs = 250
diz_loss = {'train_loss':[],'val_loss':[]}
for epoch in range(num_epochs):
  # print (epoch)
  train_loss = train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)
  val_loss = valid_epoch(encoder,decoder,device,valid_loader,loss_fn)
  print('EPOCH {}/{} \t train loss {} \t val loss {}'.format(epoch + 1, num_epochs,train_loss,val_loss))
  diz_loss['train_loss'].append(train_loss)
  diz_loss['val_loss'].append(val_loss)
  # plot_ae_outputs(model,train_dataset,device,n=10)

# Plot losses
plt.figure(figsize=(10,8))
plt.semilogy(diz_loss['train_loss'], label='Train')
plt.semilogy(diz_loss['val_loss'], label='Valid')
plt.xlabel('Epoch')
plt.ylabel('Average Loss')
#plt.grid()
plt.legend()
#plt.title('loss')
plt.show()

#Seeing how the model performs for the test unseen data. For this we choose 10 figures
#running through model.eval() and compute the loss plus we look at them visually

#Similar to plot_ae_outputs, except that this is one used to see the loss for 
#data in the test_loader. It also prints the loss for each
def plot_test_outputs(encoder,decoder,dataset,device,n=10):
    plt.figure(figsize=(26,5.5))
    for i in range(10):
      ax = plt.subplot(2,n,i+1)
      img,_ = dataset[i]
      #Notice that below i'm loading an image only, so it needs to be flatten
      #before entering the network
      img = torch.flatten(img).to(device)
      encoder.eval().to(device)
      decoder.eval().to(device)
      with torch.no_grad():
         decoded_img  = decoder(encoder(img))
         loss = loss_fn(decoded_img,img)
         print('For image {}, the loss = {}'.format(i,loss.data))
      plt.plot(img.cpu().reshape(2,128).numpy()[0],img.cpu().reshape(2,128).numpy()[1]) 
      if i == n//2:
        ax.set_title('Original images')
      ax = plt.subplot(2, n, i + 1 + n) 
      plt.plot(decoded_img.cpu().reshape(2,128).numpy()[0],decoded_img.cpu().reshape(2,128).numpy()[1]) 
      if i == n//2:
         ax.set_title('Reconstructed images')
    plt.show()  


plot_test_outputs(encoder,decoder,test_dataset,device,n=10)

#Running the autoencoder on the train data. The goal here is to obtain the
#latent variables so they can be plot and also for training a MLP

def get_latent_variables(encoder, decoder, device, dataloader):
    # Set evaluation mode for encoder and decoder
    encoder.eval()
    decoder.eval()
    with torch.no_grad(): 
        # Define the lists to store the original images, the recreated ones,
        # the latent variables and the corresponding labels
        list_img = []
        list_decoded_img = []
        list_latent = []
        list_labels = []

        for  data, label in dataloader:
            img = data
            img = img.view(img.size(0), -1).to(device) 
            # Encode and Decode data
            latent = encoder(img)
            decoded_img = decoder(latent)
            # Append the network output and the original image to the lists
            list_img.append(img.cpu())
            list_decoded_img.append(decoded_img.cpu())
            list_latent.append(latent.cpu())
            list_labels.append(label.cpu())
# Convert list into a torch.tensor
        t_img = torch.cat(list_img)
        t_decoded_img = torch.cat(list_decoded_img)
        t_latent = torch.cat(list_latent) 
        t_labels = torch.cat(list_labels)
    return t_img, t_decoded_img, t_latent, t_labels

#Creating dataloaders for the MLP. This includes train, valid and test
#Saving them on disk too

img, out_img, train_latent_var, train_labels_var = get_latent_variables(encoder,decoder,device,train_loader)
print(img.shape, out_img.shape, train_latent_var.shape, train_labels_var.shape)

img, out_img, valid_latent_var, valid_labels_var = get_latent_variables(encoder,decoder,device,valid_loader)
print(img.shape, out_img.shape, valid_latent_var.shape, valid_labels_var.shape)


img, out_img, test_latent_var, test_labels_var = get_latent_variables(encoder,decoder,device,test_loader)
print(img.shape, out_img.shape, test_latent_var.shape, test_labels_var.shape)


mlp_train_dataset, mlp_valid_dataset, mlp_test_dataset, mlp_train_loader, mlp_valid_loader, mlp_test_loader = \
get_dataloaders_fromsplitarrays(train_latent_var.numpy(),train_labels_var.numpy(), \
                                valid_latent_var.numpy(),valid_labels_var.numpy(),\
                                test_latent_var.numpy(),test_labels_var.numpy(), \
                                batch_size=50)

#Interpolating in the latent space

def get_img_from_fig(fig, dpi=180):
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=dpi)
    buf.seek(0)
    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)
    buf.close()
    plt.close()
    img = cv2.imdecode(img_arr,0)

    return img

def show_image(img):
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    ax.set_xticks([])
    ax.set_yticks([])

encoder.eval()
decoder.eval()

with torch.no_grad():
    images, labels = iter(train_loader).next()
    images = images.view(images.size(0), -1).to(device) 

    latent = encoder(images)
    latent = latent.cpu()

    mean = latent.mean(dim=0)
    print(mean)
    std = (latent - mean).pow(2).mean(dim=0).sqrt()
    print(std)


    latent = torch.randn(200, d)*std + mean
    latent = latent.to(device)
    img_recon = decoder(latent)
    img_recon = img_recon.view(img_recon.size(0), 2,128).cpu()


n_img = []
for i in range(img_recon.shape[0]):
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.set_xticks([])
    ax.set_yticks([])
    plt.close()
    ax.plot(img_recon[i][0],img_recon[i][1])
    n_img.append(get_img_from_fig(fig))

n_img = torch.from_numpy(np.asarray(n_img))
n_img = n_img[:,np.newaxis,:,:]

fig, ax = plt.subplots(figsize=(20, 8.5))
show_image(torchvision.utils.make_grid(n_img[:100],10,5))
plt.show()

img_recon.shape

# for i in range(100):
#   plt.plot(img_recon[i][0],img_recon[i][1])
# plt.show()

img_recon[0].shape

encoded_samples = []
for sample in tqdm(train_dataset):
    img = sample[0].unsqueeze(0)
    img = img.view(img.size(0), -1).to(device) 
    label = sample[1]
    encoder.eval()
    with torch.no_grad():
        encoded_img  = encoder(img)
    encoded_img = encoded_img.flatten().cpu().numpy()
    encoded_sample = {f"Enc. Variable {i}": enc for i, enc in enumerate(encoded_img)}
    encoded_sample['label0'] = label[0].numpy()
    encoded_sample['label1'] = label[1].numpy()
    encoded_sample['label2'] = label[2].numpy()
    encoded_sample['label3'] = label[3].numpy()
    encoded_samples.append(encoded_sample)
encoded_samples = pd.DataFrame(encoded_samples)
encoded_samples

px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', 
           color=encoded_samples.label0.astype(float), opacity=0.7)

px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', 
           color=encoded_samples.label1.astype(float), opacity=0.7)

px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', 
           color=encoded_samples.label2.astype(float), opacity=0.7)

px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', 
           color=encoded_samples.label3.astype(float), opacity=0.7)

tsne = TSNE(n_components=2)
tsne_results = tsne.fit_transform(encoded_samples.drop(['label0','label1','label2','label3'],axis=1))


fig = px.scatter(tsne_results, x=0, y=1,
                 color=encoded_samples.label0.astype(float),
                 labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})
fig.show()

fig = px.scatter(tsne_results, x=0, y=1,
                 color=encoded_samples.label1.astype(float),
                 labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})
fig.show()

fig = px.scatter(tsne_results, x=0, y=1,
                 color=encoded_samples.label2.astype(float),
                 labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})
fig.show()

fig = px.scatter(tsne_results, x=0, y=1,
                 color=encoded_samples.label3.astype(float),
                 labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})
fig.show()

#The following two variables are hardwired because we cannot know their values 
#before the dpi is assigned (see dpi below)
simg_dim1 = 720
simg_dim2 = 1080

d_mani = 12

def get_img_from_fig(fig, dpi=180):
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=dpi)
    buf.seek(0)
    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)
    buf.close()
    plt.close()
    img = cv2.imdecode(img_arr,0)

    return img

manifold = np.zeros((simg_dim1 * d_mani, simg_dim2 * d_mani))
grid_x = norm.ppf(np.linspace(0.95, 0.05, d_mani))
grid_y = norm.ppf(np.linspace(0.05, 0.95, d_mani))

for i, xi in enumerate(grid_x):
  for j, yi in enumerate(grid_y):
    z_sample = torch.from_numpy(np.array([[xi, yi]])).float().to(device)
    imdec = decoder(z_sample)
    imdec = imdec.view(imdec.size(0), 2,128).detach().cpu()
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.set_xticks([])
    ax.set_yticks([])
    plt.close()
    ax.plot(imdec[0][0],imdec[0][1])
    n_img = get_img_from_fig(fig)

    manifold[i * simg_dim1: (i + 1) * simg_dim1,
           j * simg_dim2: (j + 1) * simg_dim2] = n_img


fig, ax = plt.subplots(figsize=(15, 15))
ax.imshow(manifold, cmap='viridis',
          extent=[grid_x.min(), grid_x.max(), grid_y.min(), grid_y.max()])
ax.set_xlabel("$l_1$",fontsize=15);
ax.set_ylabel("$l_2$",fontsize=15);

#Saving data into gdrive

# from google.colab import drive
# drive.mount('/content/gdrive')

# torch.save(train_latent_var,'train_latent_var.pt')
# torch.save(train_latent_var,'train_labels_var.pt')

# torch.save(valid_latent_var,'valid_latent_var.pt')
# torch.save(valid_latent_var,'valid_labels_var.pt')

# torch.save(test_latent_var,'test_latent_var.pt')
# torch.save(test_latent_var,'test_labels_var.pt')

# !mv train_latent_var.pt /content/gdrive/MyDrive/neutron_reflectivity/
# !mv train_labels_var.pt /content/gdrive/MyDrive/neutron_reflectivity/
# !mv valid_latent_var.pt /content/gdrive/MyDrive/neutron_reflectivity/
# !mv valid_labels_var.pt /content/gdrive/MyDrive/neutron_reflectivity/
# !mv test_latent_var.pt /content/gdrive/MyDrive/neutron_reflectivity/
# !mv test_labels_var.pt /content/gdrive/MyDrive/neutron_reflectivity/

# torch.save(mlp_train_loader,'mlp_train_loader.pth')
# torch.save(mlp_valid_loader,'mlp_valid_loader.pth')
# torch.save(mlp_test_loader,'mlp_test_loader.pth')

# !mv mlp_train_loader.pth /content/drive/MyDrive/neutron_reflectivity/
# !mv mlp_valid_loader.pth /content/drive/MyDrive/neutron_reflectivity/
# !mv mlp_test_loader.pth /content/drive/MyDrive/neutron_reflectivity/

